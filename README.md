# CM701PC-Neural Networks & Deep Learning

### B.Tech. IV Year I Sem.

### Syllabus
<hr/>

## UNIT-01<br/>
-<b> Artificial Neural Networks Introduction</b><br/>
  > Basic models of ANN<br/>
  > important terminologies<br/>
-<b> Supervised Learning Networks</b><br/>
  > Perceptron Networks<br/>
  > Adaptive Linear Neuron<br/>
  > Back-propagation Network<br/>
  > Associative Memory Networks<br/>
  > Training Algorithms for pattern association<br/>
  > BAM and Hopfield Networks.<br/>

## UNIT-02<br/>
-<b> Unsupervised Learning Network- Introduction</b><br/>
  > Fixed Weight Competitive Nets<br/>
  > Maxnet<br/>
  > Hamming Network<br/>
  > Kohonen Self-Organizing Feature Maps<br/>
  > Learning Vector Quantization<br/>
  > Counter Propagation Networks<br/>
  > Adaptive Resonance Theory Networks<br/>
- <b>Special Networks</b>-Introduction to various networks.</b><br/>

## UNIT - 03<br/>
-<b> Introduction to Deep Learning</b><br/>
  > Historical Trends in Deep learning<br/>
  > Deep Feed - forward networks<br/>
  > Gradient-Based learning<br/>
  > Hidden Units, Architecture Design<br/>
  > Back-Propagation and Other Differentiation Algorithms<br/>

## UNIT - 04<br/>
-<b> Regularization for Deep Learning</b><br/>
  > Parameter norm Penalties<br/>
  > Norm Penalties as Constrained Optimization<br/>
  > Regularization and Under-Constrained Problems<br/>
  > Dataset Augmentation<br/>
  > Noise Robustness<br/>
  
-<b> Semi-Supervised learning</b><br/>
  > Multi-task learning, Early Stopping<br/>
  > Parameter Typing and Parameter Sharing<br/>
  > Sparse Representations<br/>
  > Bagging and other Ensemble Methods<br/>
  > Dropout<br/>
  > Adversarial Training<br/>
  > Tangent Distance, tangent Prop and Manifold, Tangent Classifier<br/>

## UNIT - 05<br/>
-<b> Optimization for Train Deep Models</b><br/>
  > Challenges in Neural Network Optimization<br/>
  > Basic Algorithms<br/>
  > Parameter Initialization Strategies<br/>
  > Algorithms with Adaptive Learning Rates<br/>
  > Approximate Second- Order Methods<br/>
  > Optimization Strategies<br/>
  > Meta-Algorithms<br/>
-<b> Applications</b><br/>
  > Large-Scale Deep Learning<br/>
  > Computer Vision<br/>
  > Speech Recognition<br/>
  > Natural Language Processing<br/>

<hr/>

## Neural Networks & Deep Learning Lab
<hr/>
<b>LIST OF EXPERIMENTS<b/>:<br/>
1.Setting up the Spyder IDE Environment and Executing a Python Program<br/>
2.Installing Keras, Tensorflow and Pytorch libraries and making use of them<br/>
3.Applying the Convolution Neural Network on computer vision problems<br/>
4.Image classification on MNIST dataset (CNN model with Fully connected layer)<br/>
5.Applying the Deep Learning Models in the field of Natural Language Processing<br/>
6.Train a sentiment analysis model on IMDB dataset, use RNN layers with LSTM/GRU notes<br/>
7.Applying the Autoencoder algorithms for encoding the real-world data<br/>
8.Applying Generative Adversial Networks for image generation and unsupervised tasks.<br/>

